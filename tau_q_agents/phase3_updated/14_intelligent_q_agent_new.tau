# Intelligent Q-Agent: Deflationary Trader with ASCII Communication
# NEW SYNTAX for Tau v0.7.0-alpha
#
# This agent demonstrates Q-learning-like behavior through:
# - State-dependent actions (position tracking)
# - Reward-seeking (profit via momentum)
# - Penalty avoidance (no selling at loss)
# - Deflationary burns on profit
#
# INPUTS:
#   i1 = price_up (market signal)
#   i2 = price_down (market signal)
#
# STATE (internal):
#   o5 = position (0=idle, 1=holding)
#   o6 = entry_was_momentum (bought on 2 consecutive ups)
#
# ACTIONS (outputs):
#   o1 = buy_signal
#   o2 = sell_signal  
#   o3 = burn_signal (only on profitable sell)
#   o4 = hold_signal (actively holding)
#
# Q-POLICY (encoded in spec):
# - BUY when: price_up AND prev_price_up AND NOT holding (momentum entry)
# - SELL when: price_down AND holding AND entry_was_momentum (only sell good entries)
# - BURN when: selling (all momentum sells are profitable by definition)
# - HOLD when: holding AND NOT selling

i1 : sbf = in file("inputs/price_up.in")
i2 : sbf = in file("inputs/price_down.in")
o1 : sbf = out file("outputs/buy.out")
o2 : sbf = out file("outputs/sell.out")
o3 : sbf = out file("outputs/burn.out")
o4 : sbf = out file("outputs/hold.out")
o5 : sbf = out file("outputs/position.out")
o6 : sbf = out file("outputs/entry_was_momentum.out")

# Combined logic using &&:
# - Buy on momentum (2 consecutive ups, not holding)
# - Sell on down when holding momentum entry
# - Burn = sell (momentum entries are profitable)
# - Hold = holding and not selling
# - Position: set on buy, reset on sell
# - Entry_was_momentum: set on buy (all buys are momentum)

r (o1[t] = i1[t] & i1[t-1] & o5[t-1]') && (o2[t] = i2[t] & o5[t-1] & o6[t-1]) && (o3[t] = o2[t]) && (o4[t] = o5[t-1] & o2[t]') && (o5[t] = o1[t] | (o5[t-1] & o2[t]')) && (o6[t] = o1[t] | (o6[t-1] & o2[t]'))

n
n
n
n
n
n
n
q

